{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aRhbR35NJo-J"},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11309,"status":"ok","timestamp":1708363949261,"user":{"displayName":"Mani Aleti","userId":"13057287046496804509"},"user_tz":-330},"id":"q47rh2BqkkgI","outputId":"0b9403ed-b082-41fd-da40-32909880f4ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Downloading dogs-vs-cats.zip to /content\n","100% 1.06G/1.06G [00:10<00:00, 44.0MB/s]\n","100% 1.06G/1.06G [00:10<00:00, 113MB/s] \n"]}],"source":["## Copy API command from the kaggle dataset\n","\n","!kaggle datasets download -d salader/dogs-vs-cats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cO8RsFNkqq8"},"outputs":[],"source":["## To unzip the dataset we got from kaggle\n","\n","import zipfile\n","zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n","zip_ref.extractall('/content')\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jy2zzRHAlO4r"},"outputs":[],"source":["## import necessary libraries for Image classification using ImageDataGenerator\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1262,"status":"ok","timestamp":1708363993189,"user":{"displayName":"Mani Aleti","userId":"13057287046496804509"},"user_tz":-330},"id":"DNYM7jB8mJLd","outputId":"59ce5f6e-13f0-46b8-f8b2-4fc058bb7ff0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n"]}],"source":["## Generators\n","\n","train_data = tf.keras.utils.image_dataset_from_directory(\n","    directory = '/content/train',\n","    labels = 'inferred',\n","    label_mode = 'int',\n","    batch_size = 32,\n","    image_size = (256, 256)\n",")\n","\n","validation_data = tf.keras.utils.image_dataset_from_directory(\n","    directory = '/content/test',\n","    labels = 'inferred',\n","    label_mode = 'int',\n","    batch_size = 32,\n","    image_size = (256, 256)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SnfV_4RUzpU"},"outputs":[],"source":["## Normalize the data between 0 and 1\n","\n","def process(image, label):\n","  image = tf.cast(image/255. ,tf.float32)\n","  return image, label\n","train_data = train_data.map(process)\n","validation_data = validation_data.map(process)"]},{"cell_type":"markdown","metadata":{"id":"GUMnlzcIW7Ns"},"source":["Convolution Neural Network with Variation 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kD2JIPcVtvG"},"outputs":[],"source":["## Build a Basic CNN Model for image classification\n","\n","model1 = Sequential()\n","\n","model1.add(Conv2D(32, kernel_size = (3,3), padding = 'valid', activation = 'relu', input_shape = (256,256,3)))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Conv2D(64, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Conv2D(128, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Flatten())\n","\n","model1.add(Dense(128, activation='relu'))\n","model1.add(Dropout(0.1))\n","model1.add(Dense(64, activation='relu'))\n","model1.add(Dropout(0.1))\n","model1.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1708364006847,"user":{"displayName":"Mani Aleti","userId":"13057287046496804509"},"user_tz":-330},"id":"su71C83pXzar","outputId":"e026a9a0-b3b1-4ad3-80fb-2bb7950f42e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 254, 254, 32)      896       \n","                                                                 \n"," batch_normalization (Batch  (None, 254, 254, 32)      128       \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 125, 125, 64)      256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 60, 60, 128)       512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 115200)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               14745728  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 14848193 (56.64 MB)\n","Trainable params: 14847745 (56.64 MB)\n","Non-trainable params: 448 (1.75 KB)\n","_________________________________________________________________\n"]}],"source":["model1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sp-IMV28X8kq"},"outputs":[],"source":["model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8w6lgaksYWqW","outputId":"dd5d9fa3-e182-4c87-c046-e5352c5aae55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","625/625 [==============================] - 4033s 6s/step - loss: 1.4513 - accuracy: 0.6093 - val_loss: 0.6051 - val_accuracy: 0.6628\n","Epoch 2/10\n","230/625 [==========>...................] - ETA: 38:40 - loss: 0.5899 - accuracy: 0.7027"]}],"source":["history_of_model1 = model1.fit(train_data, epochs = 10, validation_data = validation_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvICf_OnZhu6"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history_of_model1.history['accuracy'], color = 'red', label = 'train')\n","plt.plot(history_of_model1.history['val_accuracy'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4CSM1picZoe"},"outputs":[],"source":["plt.plot(history_of_model1.history['loss'], color = 'red', label = 'train')\n","plt.plot(history_of_model1.history['val_loss'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4zdpI3rckUQ"},"outputs":[],"source":["import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_aWQmEQgo0D"},"outputs":[],"source":["test_img = cv2.imread('/content/cat.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCHAHLm2gv3i"},"outputs":[],"source":["plt.imshow(test_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7V8aHg53gzRt"},"outputs":[],"source":["test_img.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhYilqKfhCi2"},"outputs":[],"source":["test_img = cv2.resize(test_img, (256, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWQ7PkqhhSFG"},"outputs":[],"source":["test_input = test_img.reshape((1, 256, 256, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AgHMscvzhkDm"},"outputs":[],"source":["model.predict(test_input)"]},{"cell_type":"markdown","metadata":{"id":"ULAFYirK0LBi"},"source":["The implemented Convolutional Neural Network (CNN) model represents a fundamental yet effective approach to image classification tasks. The combination of the Adam optimizer, binary_cross entropy metric and Dropout 10%, and the chosen CNN architecture underscores a thoughtful design aimed at striking a balance between model complexity and computational efficiency., making it well-suited for visual recognition tasks. With a training duration spanning 10 epochs, Notably, the achieved accuracy surpassing 95% indicates the model's proficiency in correctly classifying instances, a testament to its effectiveness in capturing intricate features within the images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBJ9jS2A0O4A"},"outputs":[],"source":["## Build a Basic CNN Model for image classification\n","\n","model1 = Sequential()\n","\n","model1.add(Conv2D(32, kernel_size = (3,3), padding = 'valid', activation = 'relu', input_shape = (256,256,3)))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Conv2D(64, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Conv2D(128, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model1.add(BatchNormalization())\n","model1.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model1.add(Flatten())\n","\n","model1.add(Dense(128, activation='relu'))\n","model1.add(Dropout(0.2))\n","model1.add(Dense(64, activation='relu'))\n","model1.add(Dropout(0.2))\n","model1.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57QKT94D0viG"},"outputs":[],"source":["model1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QR9FIqo0y4P"},"outputs":[],"source":["model1.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkjOTqph0859"},"outputs":[],"source":["history_of_model1 = model1.fit(train_data, epochs = 10, validation_data = validation_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MaDb2R31Ffa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history_of_model1.history['accuracy'], color = 'red', label = 'train')\n","plt.plot(history_of_model1.history['val_accuracy'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0zyQqKJ4TuP"},"outputs":[],"source":["plt.plot(history_of_model1.history['loss'], color = 'red', label = 'train')\n","plt.plot(history_of_model1.history['val_loss'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZEeXFy2H4GL1"},"source":["The implemented Convolutional Neural Network (CNN) model represents a fundamental yet effective approach to image classification tasks. The combination of the SGD optimizer, binary_cross entropy metric and Dropout 20%, and the chosen CNN architecture underscores a thoughtful design aimed at striking a balance between model complexity and computational efficiency., making it well-suited for visual recognition tasks. With a training duration spanning 10 epochs, Notably, the achieved accuracy surpassing 90% indicates the model's proficiency in correctly classifying instances, a testament to its effectiveness in capturing intricate features within the images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuZKgM_y6sEY"},"outputs":[],"source":["## Build a Basic CNN Model for image classification\n","\n","model2 = Sequential()\n","\n","model2.add(Conv2D(32, kernel_size = (3,3), padding = 'valid', activation = 'relu', input_shape = (256,256,3)))\n","model2.add(BatchNormalization())\n","model2.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model2.add(Conv2D(64, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model2.add(BatchNormalization())\n","model2.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model2.add(Conv2D(128, kernel_size = (3,3), padding = 'valid', activation = 'relu'))\n","model2.add(BatchNormalization())\n","model2.add(MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid'))\n","\n","model2.add(Flatten())\n","\n","model2.add(Dense(128, activation='relu'))\n","model2.add(Dropout(0.2))\n","model2.add(Dense(64, activation='relu'))\n","model2.add(Dropout(0.2))\n","model2.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZsMEfHY_7ZF"},"outputs":[],"source":["model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MT3YNTElAxyd"},"outputs":[],"source":["opt = keras.optimizers.Adam(learning_rate = 0.01)\n","model2.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkhedmDjBKB9"},"outputs":[],"source":["history_of_model2 = model2.fit(train_data, epochs = 10, validation_data = validation_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIXTZX0JEPzA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history_of_model2.history['accuracy'], color = 'red', label = 'train')\n","plt.plot(history_of_model2.history['val_accuracy'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqtNTiUiEQgj"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history_of_model2.history['loss'], color = 'red', label = 'train')\n","plt.plot(history_of_model2.history['val_loss'], color = 'blue', label = 'validation')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"LdpkhzOADMXJ"},"source":["The implemented Convolutional Neural Network (CNN) model represents a fundamental yet effective approach to image classification tasks. The combination of the Adam optimizer with learning rate 0.01, binary_cross entropy metric and  Dropout 20%, and the chosen CNN architecture underscores a thoughtful design aimed at striking a balance between model complexity and computational efficiency., making it well-suited for visual recognition tasks. With a training duration spanning 10 epochs, Notably, the achieved accuracy around 50% indicates the model's proficiency in correctly classifying instances, a testament to its effectiveness in capturing intricate features within the images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rz_-dlGDe80"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOkNN8U+5DEQb9+wUCmaT1G"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}